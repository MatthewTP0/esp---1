{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ac19258",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision\n",
    "from torchvision import transforms, models\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchmetrics\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import TensorBoardLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2163bf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowersClassifierDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, batch_size: int=16, data_dir: str = r\"C:\\Users\\matth\\OneDrive\\Desktop\\school\\archive (1)\\flower_data\\flower_data\"):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        # Augmentation policy for training set\n",
    "    def setup(self, stage):\n",
    "        transform_train = transforms.Compose([\n",
    "              transforms.RandomResizedCrop(size=256),\n",
    "              transforms.RandomRotation(degrees=15),\n",
    "              transforms.RandomHorizontalFlip(),\n",
    "              transforms.CenterCrop(size=224),\n",
    "              transforms.ToTensor(),\n",
    "              transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        # Preprocessing steps applied to validation and test set.\n",
    "        transform_test = transforms.Compose([\n",
    "              transforms.Resize(size=256),\n",
    "              transforms.CenterCrop(size=224),\n",
    "              transforms.ToTensor(),\n",
    "              transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        tr_data = ImageFolder(self.data_dir + '\\\\train', transform_train)\n",
    "        self.test_dataset = ImageFolder(self.data_dir + '\\\\valid', transform_test)\n",
    "        \n",
    "  \n",
    "    # use 20% of training data for validation (I changed it to 50)\n",
    "        train_set_size = int(len(tr_data) * 0.05)\n",
    "        valid_set_size = len(tr_data) - train_set_size\n",
    "\n",
    "    # split the train set into two\n",
    "        seed = torch.Generator().manual_seed(42)\n",
    "        self.train_dataset, self.val_dataset = random_split(tr_data, [train_set_size, valid_set_size], generator=seed)\n",
    "\n",
    "            \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, num_workers=9)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, num_workers=9)\n",
    "    \n",
    "   # this code runs if only test and train are used, when this is done the validation loop is skipped:\n",
    "    # def train_dataloader(self):\n",
    "      #  return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=8)\n",
    "\n",
    "   # def test_dataloader(self):\n",
    "      #  return DataLoader(self.test_dataset, batch_size=self.batch_size, num_workers=8)\n",
    "    \n",
    "    # Error arises upon adding  \n",
    "    #def val_dataloader(self):\n",
    "        # return DataLoader(self.val_dataset, batch_size=self.batch_size, num_workers=8)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc8018b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = r'C:\\Users\\matth\\OneDrive\\Desktop\\school\\archive (1)\\flower_data\\flower_data'\n",
    "Batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "443e88e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowersClassifier(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.criterion =  nn.CrossEntropyLoss()\n",
    "        self.backbone = models.resnet18(pretrained=True)\n",
    "        self.linear = nn.Linear(1000, 102)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        x = self.linear(x)\n",
    "        return(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log(\"mytrain_loss\", loss, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return {'loss': loss, 'log': loss}\n",
    "        \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self.forward(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log(\"val_loss\", loss, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return {'val_loss': loss, \"pred\": y_hat.detach(), \"labels\": y}\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a96d6153",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\matth\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\matth\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "model = FlowersClassifier()\n",
    "datamodule = FlowersClassifierDataModule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eefee55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(accelerator=\"gpu\", devices=1, max_epochs=2, log_every_n_steps=16, callbacks=[EarlyStopping(monitor=\"mytrain_acc_step\", mode=\"min\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3770132",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type             | Params\n",
      "-----------------------------------------------\n",
      "0 | criterion | CrossEntropyLoss | 0     \n",
      "1 | backbone  | ResNet           | 11.7 M\n",
      "2 | linear    | Linear           | 102 K \n",
      "-----------------------------------------------\n",
      "11.8 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.8 M    Total params\n",
      "47.166    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0e9e4163ffe4b74a6b004bc31e86e2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model, datamodule)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
